lets understand time complexities better in this :


O(1) means one operation ex: in an array [1,3,4,5,6] so a[3] = 5 


O(log n) 
-----
check if the element is present in this array or not like 
 
 [1,2,3,4,5,6,9,10]


now this is sorted array if we wants to check the element 9 in it 
 it will check the length of the array like (0 + len)/2 then we go to middle element and compare the 9 with that if it is small move left or right 

so right 

again until we find it 

O(n)
-----

O(n) is iterating over all the elements like 
check if the element is present in this array or not like

 [1,7,8,10,4,5] 

so to check 2 is in the array or not i have to check the entire array like the linear search so O(n) the worst case 

O(n log n)
----------

now lets take 

[1.4.2.3.6.7.9]

we are having two sorting techniques 
1.Quick sort
2.Merge sort 
if we sort the array using these two techniques the array will sort 

but time complexity will be O(n log n) 


O(n^2)
------

using two for loops :

for i in range(a):
    for j in range(a) 



O(n^3) 
-----
using three for loops :

for i in range(a):
    for j in range(a):
      for k in range(a):


O(2^n) and O(n !) we dont discuss these and dont use also 

